Class distribution for binary labels .....
(array([ 0.,  1.]), array([23639, 50428]))
Class distribution for ternary labels .....
(array([ 1.,  2.,  3.]), array([11900, 27829, 34338]))

Learning Curve with RandomForestClassifier and GradientBoostingRegressor ....
Regression .....
Ran iteration 1 with 5925 training data points with 0.221240 training RMSE and 0.225997 test RMSE
Ran iteration 2 with 11850 training data points with 0.225024 training RMSE and 0.225997 test RMSE
Ran iteration 3 with 17775 training data points with 0.224709 training RMSE and 0.225997 test RMSE
Ran iteration 4 with 23701 training data points with 0.225253 training RMSE and 0.225991 test RMSE
Ran iteration 5 with 29626 training data points with 0.224763 training RMSE and 0.225991 test RMSE
Ran iteration 6 with 35551 training data points with 0.222939 training RMSE and 0.225991 test RMSE
Ran iteration 7 with 41477 training data points with 0.221530 training RMSE and 0.225991 test RMSE
Ran iteration 8 with 47402 training data points with 0.221431 training RMSE and 0.225991 test RMSE
Ran iteration 9 with 53327 training data points with 0.221966 training RMSE and 0.225991 test RMSE
Ran iteration 10 with 59253 training data points with 0.222547 training RMSE and 0.225991 test RMSE
 ============================================================
ternary classification .....
Ran iteration 1 with 5925 training data points with 0.008439 training error and 0.463075 test error
Ran iteration 2 with 11850 training data points with 0.006498 training error and 0.467868 test error
Ran iteration 3 with 17775 training data points with 0.006751 training error and 0.469488 test error
Ran iteration 4 with 23701 training data points with 0.006835 training error and 0.466653 test error
Ran iteration 5 with 29626 training data points with 0.006346 training error and 0.465506 test error
Ran iteration 6 with 35551 training data points with 0.006441 training error and 0.463008 test error
Ran iteration 7 with 41477 training data points with 0.006437 training error and 0.464763 test error
Ran iteration 8 with 47402 training data points with 0.006392 training error and 0.467193 test error
Ran iteration 9 with 53327 training data points with 0.006001 training error and 0.466788 test error
Ran iteration 10 with 59253 training data points with 0.006464 training error and 0.462535 test error
 ============================================================
binary classification .....
Ran iteration 1 with 5925 training data points with 0.006076 training error and 0.299649 test error
Ran iteration 2 with 11850 training data points with 0.005232 training error and 0.302822 test error
Ran iteration 3 with 17775 training data points with 0.005288 training error and 0.302822 test error
Ran iteration 4 with 23701 training data points with 0.005063 training error and 0.303497 test error
Ran iteration 5 with 29626 training data points with 0.005502 training error and 0.308154 test error
Ran iteration 6 with 35551 training data points with 0.004951 training error and 0.303294 test error
Ran iteration 7 with 41477 training data points with 0.005159 training error and 0.299919 test error
Ran iteration 8 with 47402 training data points with 0.005612 training error and 0.303632 test error
Ran iteration 9 with 53327 training data points with 0.005082 training error and 0.300189 test error
Ran iteration 10 with 59253 training data points with 0.004979 training error and 0.299176 test error


10 fold cv for binary classification using RandomForests had accuracy 0.689 and std. dev 0.020
10 fold cv for binary classification using AdaBoost had accuracy 0.632 and std. dev 0.032
10 fold cv for ternary classification using RandomForests had accuracy 0.526 and std. dev 0.024
10 fold cv for ternary classification using AdaBoost had accuracy 0.481 and std. dev 0.029
10 fold cv for regression using GradientBoostingRegressor had RMSE 0.180 and std. dev 0.035



Getting Feature importances and F1 scores for binary classification .....
==================================================================
- F1 scores and confusion-matrix using RandomForestClassifier Classifier ...
	Confusion Matrix:- [[2002 2726]
					[1830 8256]]

	F1 Scores:- [ 0.46775701  0.78374786]
	Feature importance => (0.0901, 0.089, 0.0762, 0.0742, 0.0679) ('tf_idf_scores', 'edit_distance_desc', 'edit_distance_title', 'longest_match', 'rmse_desc')
- F1 scores and confusion-matrix using AdaBoost Classifier ...
		Confusion Matrix:- [[3135 1593]
 					[3721 6365]]
		F1 Scores:-	[ 0.54126381  0.70549767]

Getting Feature importances and F1 scores for ternary classification .....
==================================================================
- F1 scores and confusion-matrix using RandomForestClassifier Classifier ...
	Confusion Matrix:- [[ 581 1195  604]
						[ 665 2697 2204]
						[ 298 1999 4571]]
	F1 scores:- [ 0.2961264   0.47080388  0.64167895]
	Feature importance => (0.0913, 0.0881, 0.0792, 0.0709, 0.0692) ('edit_distance_desc', 'tf_idf_scores', 'edit_distance_title', 'longest_match', 'rmse_desc')

- F1 scores and confusion-matrix using AdaBoost Classifier ...
 	Confusion Matrix:-  [[1373  635  372]
						  [1980 1973 1613]
						  [1371 1615 3882]]
	F1 Scores:- [ 0.38654279  0.40310553  0.60965842]
[ 0.38654279  0.40310553  0.60965842]


10 fold cv for binary classification using XGBoost had accuracy 0.702 and std. dev 0.009
10 fold cv for ternary classification using XGBoost had accuracy 0.544 and std. dev 0.023
10 fold cv for regression using XGBoost had RMSE 0.180 and std. dev 0.035
10 fold cv for binary classification using stacking had accuracy 0.690 and std. dev 0.019